---
# yaml-language-server: $schema=https://schemas.rzegocki.dev/monitoring.coreos.com/prometheusrule_v1.json
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: kube-prometheus-stack-prometheus
    role: alert-rules
  name: ceph-extra
spec:
  groups:
    - name: ceph-extra.rules
      rules:
        - alert: CephOSDHighWriteThroughput
          expr: sum(rate(ceph_osd_op_w_in_bytes[5m])) > 20971520
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Ceph OSDs are under high write pressure
            description: |-
              Ceph OSDs have a lot of writes. Use
              sum(rate(ceph_osd_op_w_in_bytes[5m])) > 20971520
              metric to find the culprit and investigate.
        - alert: CephOSDHighWriteIOPS
          expr: sum(rate(ceph_osd_op_w[10m])) > 40
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Ceph OSDs use a lot of IOPS
            description: |-
              Ceph OSDs have a lot of writes. Use
              sum(rate(ceph_osd_op_w_in_bytes[5m])) > 20971520
              metric to find the culprit and investigate.
        - alert: CephPGImbalancePersistent
          annotations:
            summary: PGs are not balanced across OSDs
            description: OSD {{ `{{ $labels.ceph_daemon }}` }} on {{ `{{ $labels.hostname }}` }} deviates
              by more than 30% from average PG count.
          expr: |
            abs(
              ((ceph_osd_numpg{ceph_daemon=~"osd.[123]"} > 0) - on (job) group_left
              avg(ceph_osd_numpg{ceph_daemon=~"osd.[123]"} > 0) by (job)) /
              on (job) group_left avg(ceph_osd_numpg{ceph_daemon=~"osd.[123]"} > 0) by (job)
            ) * on (ceph_daemon) group_left(hostname) ceph_osd_metadata > 0.30
          for: 5m
          labels:
            oid: 1.3.6.1.4.1.50495.1.2.1.4.5
            severity: warning
            type: ceph_default
        - alert: CephPGImbalanceEphemeral
          annotations:
            summary: PGs are not balanced across OSDs
            description: OSD {{ `{{ $labels.ceph_daemon }}` }} on {{ `{{ $labels.hostname }}` }} deviates
              by more than 30% from average PG count.
          expr: |
            abs(
              ((ceph_osd_numpg{ceph_daemon=~"osd.[045]"} > 0) - on (job) group_left
              avg(ceph_osd_numpg{ceph_daemon=~"osd.[045]"} > 0) by (job)) /
              on (job) group_left avg(ceph_osd_numpg{ceph_daemon=~"osd.[045]"} > 0) by (job)
            ) * on (ceph_daemon) group_left(hostname) ceph_osd_metadata > 0.30
          for: 5m
          labels:
            oid: 1.3.6.1.4.1.50495.1.2.1.4.5
            severity: warning
            type: ceph_default
