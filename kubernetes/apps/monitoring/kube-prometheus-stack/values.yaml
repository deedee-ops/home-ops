---
kube-prometheus-stack:
  crds:
    enabled: true
  cleanPrometheusOperatorObjectNames: true
  defaultRules:
    create: true
  alertmanager:
    ingress:
      enabled: true
      ingressClassName: internal
      annotations:
        gethomepage.dev/enabled: "true"
        gethomepage.dev/group: Monitoring
        gethomepage.dev/name: Alertmanager
        gethomepage.dev/icon: alertmanager.png
        gethomepage.dev/description: Alerts Management
        gethomepage.dev/pod-selector: "app.kubernetes.io/name in ( alertmanager )"
      hosts:
        - "alertmanager.<path:kubernetes/data/internal/base#ROOT_DOMAIN>"
      tls:
        - hosts:
            - "alertmanager.<path:kubernetes/data/internal/base#ROOT_DOMAIN>"
      path: /
    config:
      global:
        smtp_hello: "<path:kubernetes/data/internal/smtp-relay#INGRESS_DOMAIN>"
        smtp_smarthost: "smtp-relay.networking.svc.cluster.local:25"
        smtp_from: "<path:kubernetes/data/internal/base#MAIL_FROM_CLUSTER>"
        smtp_require_tls: false
      inhibit_rules:
        - source_matchers:
            - severity="critical"
          target_matchers:
            - severity=~"warning|info"
          equal:
            - namespace
            - alertname
        - source_matchers:
            - severity="warning"
          target_matchers:
            - severity="info"
          equal:
            - namespace
            - alertname
        - source_matchers:
            - alertname="InfoInhibitor"
          target_matchers:
            - severity="info"
          equal:
            - namespace
      route:
        receiver: email-cluster
        group_by:
          - alertname
          - job
        continue: false
        routes:
          - receiver: "null"
            matchers:
              - alertname = InfoInhibitor
          - receiver: healthchecks
            matchers:
              - alertname = Watchdog
            repeat_interval: 15m
          - receiver: pushover
            continue: true
            matchers:
              - severity = "critical"
          - receiver: email-cluster
            continue: true
            matchers:
              - severity = "critical"
          - receiver: discord-csp
            matchers:
              - alertname = CSPAlert
          - receiver: email-hypervisor
            matchers:
              - instance =~ "<path:kubernetes/data/internal/base#IP_HYPERVISOR>:[0-9]+"
              - instance =~ "<path:kubernetes/data/internal/base#IP_ROUTER>:[0-9]+"
              - instance =~ "<path:kubernetes/data/internal/base#IP_SUPERVISOR>:[0-9]+"
          - receiver: email-nas
            matchers:
              - instance =~ "<path:kubernetes/data/internal/base#IP_NAS>:[0-9]+"
              - instance =~ "<path:kubernetes/data/internal/base#IP_PBS>:[0-9]+"
        group_wait: 1m
        group_interval: 10m
        repeat_interval: 12h
      receivers:
        - name: "null"
        - name: "email-hypervisor"
          email_configs:
            - from: "<path:kubernetes/data/internal/base#MAIL_FROM_HYPERVISOR>"
              to: "<path:kubernetes/data/internal/smtp-relay#INGRESS_MAINTENANCE_EMAIL>"
        - name: "email-cluster"
          email_configs:
            - from: "<path:kubernetes/data/internal/base#MAIL_FROM_CLUSTER>"
              to: "<path:kubernetes/data/internal/smtp-relay#INGRESS_MAINTENANCE_EMAIL>"
        - name: "email-nas"
          email_configs:
            - from: "<path:kubernetes/data/internal/base#MAIL_FROM_NAS>"
              to: "<path:kubernetes/data/internal/smtp-relay#INGRESS_MAINTENANCE_EMAIL>"
        - name: "discord-csp"
          discord_configs:
            - webhook_url: "<path:kubernetes/data/internal/kube-prometheus-stack#DISCORD_CSP_WEBHOOK>"
              message: '{{ template "homelab.discord.message" . }}'
              title: '{{ template "homelab.discord.title" . }}'
        - name: "healthchecks"
          webhook_configs:
            - send_resolved: false
              url: "<path:kubernetes/data/internal/kube-prometheus-stack#EXTERNAL_PING_URL>"
              http_config:
                follow_redirects: true
        - name: "pushover"
          pushover_configs:
            - html: true
              message: '{{ template "homelab.pushover.message" . }}'
              priority: 1
              title: '{{ template "homelab.pushover.title" . }}'
              token: "<path:kubernetes/data/internal/kube-prometheus-stack#ALERTMANAGER_PUSHOVER_TOKEN>"
              url_title: View in Alertmanager
              user_key: "<path:kubernetes/data/internal/kube-prometheus-stack#PUSHOVER_USER_KEY>"
      templates:
        - '/etc/alertmanager/config/*.tmpl'
    templateFiles:
      discord_msg.tmpl: |-
        {{ define "homelab.discord.title" }}
            Fire! {{ .GroupLabels.SortedPairs.Values | join " " }}
        {{ end }}

        {{ define "homelab.discord.message" }}
            {{ range .Alerts.Firing }}
              Alert: **{{ printf "%.150s" .Annotations.summary }}** ({{ .Labels.severity }})
              Description: {{ printf "%.150s" .Annotations.description }}
              Alertname: {{ .Labels.alertname }}
              Namespace: {{ .Labels.namespace }}
              Service: {{ .Labels.service }}
            {{ end }}

            {{ if gt (len .Alerts.Resolved) 0 }}
                Also {{ .Alerts.Resolved | len }} resolved alerts.
            {{ end }}
        {{ end }}
      pushover_msg.tmpl: |-
        {{ define "homelab.pushover.title" }}
          [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}]
          {{ .CommonLabels.alertname }}
        {{ end }}
        {{ define "homelab.pushover.message" }}
            {{- range .Alerts }}
              {{- if ne .Annotations.description "" }}
                {{ .Annotations.description }}
              {{- else if ne .Annotations.summary "" }}
                {{ .Annotations.summary }}
              {{- else if ne .Annotations.message "" }}
                {{ .Annotations.message }}
              {{- else }}
                Alert description not available
              {{- end }}
              {{- if gt (len .Labels.SortedPairs) 0 }}
                <small>
                {{- range .Labels.SortedPairs }}
                  <b>{{ .Name }}:</b> {{ .Value }}
                {{- end }}
                </small>
              {{- end }}
            {{- end }}
        {{ end }}
    alertmanagerSpec:
      replicas: 2
      podMetadata:
        annotations:
          reloader.stakater.com/auto: "true"
      podAntiAffinity: hard
      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: local-path
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 64Mi
    podDisruptionBudget:
      enabled: false
  grafana:
    enabled: false
  kubeApiServer:
    enabled: true
  kubelet:
    enabled: true
  kubeControllerManager:
    enabled: true
    endpoints: &controlplane
      - <path:kubernetes/data/internal/base#IP_CONTROLPLANE_1>
      - <path:kubernetes/data/internal/base#IP_CONTROLPLANE_2>
      - <path:kubernetes/data/internal/base#IP_CONTROLPLANE_3>
    service:
      enabled: true
      port: 10257
      targetPort: 10257
    serviceMonitor:
      enabled: true
      https: true
      insecureSkipVerify: true
  coreDns:
    enabled: true
  kubeEtcd:
    enabled: true
    endpoints: *controlplane
    service:
      enabled: true
      port: 2381
      targetPort: 2381
  kubeScheduler:
    enabled: true
    endpoints: *controlplane
    service:
      enabled: true
      port: 10259
      targetPort: 10259
    serviceMonitor:
      enabled: true
      https: true
      insecureSkipVerify: true
  # cilium does kubeproxy
  kubeProxy:
    enabled: false
  kubeStateMetrics:
    enabled: true
  # subchart configuration
  kube-state-metrics:
    containerSecurityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop:
          - ALL
    resources:
      limits:
        memory: 128Mi
      requests:
        memory: 32Mi
  nodeExporter:
    enabled: true
  prometheus-node-exporter:
    fullnameOverride: node-exporter
    prometheus:
      monitor:
        enabled: true
        relabelings:
          - action: replace
            regex: (.*)
            replacement: $1
            sourceLabels:
              - __meta_kubernetes_pod_node_name
            targetLabel: homelab_node
  prometheusOperator:
    serviceMonitor:
      sampleLimit: 500
  prometheus:
    ingress:
      enabled: true
      ingressClassName: internal
      annotations:
        gethomepage.dev/enabled: "true"
        gethomepage.dev/group: Monitoring
        gethomepage.dev/name: Prometheus
        gethomepage.dev/icon: prometheus.png
        gethomepage.dev/description: Metrics Collector
        gethomepage.dev/pod-selector: "app.kubernetes.io/name in ( prometheus )"
      hosts:
        - "prometheus.<path:kubernetes/data/internal/base#ROOT_DOMAIN>"
      tls:
        - hosts:
            - "prometheus.<path:kubernetes/data/internal/base#ROOT_DOMAIN>"
      path: /
    prometheusSpec:
      replicas: 1
      podMetadata:
        labels:
          route-to/nas: "true"
      podAntiAffinity: hard
      replicaExternalLabelName: __replica__
      ruleSelectorNilUsesHelmValues: false
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      probeSelectorNilUsesHelmValues: false
      scrapeConfigSelectorNilUsesHelmValues: false
      walCompression: true
      enableFeaturs:
        - auto-gomaxprocs
        - memory-snapshot-on-shutdown
        - new-service-discovery-manager
      retention: 7d
      retentionSize: 15GB
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: local-path
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 50Gi
