---
# yamllint disable rule:line-length
# renovate: datasource=docker depName=ghcr.io/siderolabs/installer
# yaml-language-server: $schema=https://raw.githubusercontent.com/siderolabs/talos/refs/tags/v1.11.5/pkg/machinery/config/schemas/config.schema.json
# yamllint enable rule:line-length

version: v1alpha1
machine:
  ca:
    crt: '{{ ENV[".machine.ca.crt"] }}'
    # {% if ENV.IS_CONTROLPLANE %}
    key: '{{ ENV[".machine.ca.key"] }}'
    # {% endif %}

  features:
    apidCheckExtKeyUsage: true
    diskQuotaSupport: true
    hostDNS:
      enabled: true
      forwardKubeDNSToHost: false
      resolveMemberNames: true
    kubePrism:
      enabled: true
      port: 7445
    # {% if ENV.IS_CONTROLPLANE %}
    kubernetesTalosAPIAccess:
      allowedKubernetesNamespaces:
        - system-upgrade
      allowedRoles:
        - "os:admin"
      enabled: true
    # {% endif %}

    rbac: true
    stableHostname: true
  files:
    # Spegel
    - op: create
      path: /etc/cri/conf.d/20-customization.part
      content: |
        [plugins."io.containerd.cri.v1.images"]
          discard_unpacked_layers = false
        [plugins."io.containerd.cri.v1.runtime"]
          cdi_spec_dirs = ["/var/cdi/static", "/var/cdi/dynamic"]
          device_ownership_from_security_context = true
    # NFS
    - op: overwrite
      path: /etc/nfsmount.conf
      permissions: 0o644
      content: |
        [ NFSMount_Global_Options ]
        nfsvers=4.2
        hard=True
        nconnect=16
        noatime=True
  install:
    diskSelector:
      model: "WD Blue SN570 500GB"
    image: talos.ajgon.casa/installer-secureboot/4f7de4c4221bd9dde2b558a9655463c23b2173115f2df8d7f84d85af5da14a09:v1.11.5
    wipe: true
  kernel:
    modules:
      - name: nbd
      - name: thunderbolt
      - name: thunderbolt_net
  kubelet:
    defaultRuntimeSeccompProfileEnabled: true
    disableManifestsDirectory: true
    extraConfig:
      featureGates:
        UserNamespacesSupport: true
        UserNamespacesPodSecurityStandards: true
      serializeImagePulls: false
    image: "ghcr.io/siderolabs/kubelet:v1.34.2"
    nodeIP:
      validSubnets:
        - 192.168.42.0/26
  network:
    interfaces:
      - deviceSelector:
          hardwareAddr: 48:21:0b:51:*
        dhcp: true
        # mtu: 9000
  nodeLabels:
    node.kubernetes.io/gpu: "true"
    topology.kubernetes.io/region: homelab
    topology.kubernetes.io/zone: deedee
  sysctls:
    fs.inotify.max_user_instances: "8192" # More inotify events
    fs.inotify.max_user_watches: "1048576" # More inotify events
    net.core.default_qdisc: fq # Enable pacing and fair queueing for smoother flow control
    net.core.rmem_max: "67108864" # Cloudflared / QUIC
    net.core.wmem_max: "67108864" # Cloudflared / QUIC
    net.ipv4.neigh.default.gc_thresh1: "4096" # ARP neighbor GC thresholds
    net.ipv4.neigh.default.gc_thresh2: "8192" # ARP neighbor GC thresholds
    net.ipv4.neigh.default.gc_thresh3: "16384" # ARP neighbor GC thresholds
    net.ipv4.tcp_congestion_control: bbr # Use BBR congestion control for fast, low-latency delivery
    net.ipv4.tcp_fastopen: "3" # Send and accept data in the opening SYN packet
    net.ipv4.tcp_mtu_probing: "1" # Enable MTU probing in case of ICMP blackholes
    net.ipv4.tcp_window_scaling: "1" # Enable TCP window scaling to go beyond 64KB receive windows
    net.ipv6.conf.all.disable_ipv6: "1" # Not used, causes lot of headaches
    sunrpc.tcp_max_slot_table_entries: "128" # Faster NFS
    sunrpc.tcp_slot_table_entries: "128" # Faster NFS
    user.max_user_namespaces: "11255" # User Namespaces
    vm.nr_hugepages: "1024" # PostgreSQL

    # net.ipv4.tcp_rmem: 4096 87380 8388608  # Conservative receive buffer tuning (min, default, max in bytes)
    # net.ipv4.tcp_wmem: 4096 65536 8388608  # Conservative send buffer tuning (min, default, max in bytes)
    net.ipv4.tcp_rmem: 4096 87380 33554432 # Performant receive buffer tuning (min, default, max in bytes)
    net.ipv4.tcp_wmem: 4096 65536 33554432 # Performant send buffer tuning (min, default, max in bytes)

  systemDiskEncryption:
    state:
      provider: luks2
      keys:
        - slot: 0
          tpm: {}
    ephemeral:
      provider: luks2
      keys:
        - slot: 0
          tpm: {}

  token: '{{ ENV[".machine.token"] }}'
  udev:
    rules:
      # Intel GPU
      - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"
      # Thunderbolt - Disable Power Management
      - ACTION=="add", SUBSYSTEM=="thunderbolt", ATTR{power/control}="on"
      # Thunderbolt - Ensure proper cooperation with kexec
      - ACTION=="add", SUBSYSTEM=="thunderbolt", ATTR{authorized}=="0", ATTR{authorized}="1"

cluster:
  ca:
    crt: '{{ ENV[".cluster.ca.crt"] }}'
    # {% if ENV.IS_CONTROLPLANE %}
    key: '{{ ENV[".cluster.ca.key"] }}'
    # {% endif %}

  clusterName: deedee
  controlPlane:
    endpoint: https://deedee.internal:6443
  discovery:
    enabled: true
    registries:
      kubernetes:
        disabled: true
      service:
        disabled: false
  id: '{{ ENV[".cluster.id"] }}'
  network:
    cni:
      name: none
    dnsDomain: cluster.local
    podSubnets:
      - 172.30.0.0/16
    serviceSubnets:
      - 172.31.0.0/16
  secret: '{{ ENV[".cluster.secret"] }}'
  token: '{{ ENV[".cluster.token"] }}'

  # {% if ENV.IS_CONTROLPLANE %}
  aggregatorCA:
    crt: '{{ ENV[".cluster.aggregatorCA.crt"] }}'
    key: '{{ ENV[".cluster.aggregatorCA.key"] }}'
  allowSchedulingOnControlPlanes: true
  apiServer:
    auditPolicy:
      apiVersion: audit.k8s.io/v1
      kind: Policy
      rules:
        - level: Metadata
    admissionControl:
      - name: PodSecurity
        configuration:
          apiVersion: pod-security.admission.config.k8s.io/v1alpha1
          defaults:
            audit: restricted
            audit-version: latest
            enforce: baseline
            enforce-version: latest
            warn: restricted
            warn-version: latest
          exemptions:
            namespaces:
              - kube-system
            runtimeClasses: []
            usernames: []
          kind: PodSecurityConfiguration
    certSANs:
      - deedee.internal
    disablePodSecurityPolicy: true
    extraArgs:
      enable-aggregator-routing: "true"
      feature-gates: MutatingAdmissionPolicy=true
      runtime-config: admissionregistration.k8s.io/v1beta1=true
    image: registry.k8s.io/kube-apiserver:v1.34.2
  controllerManager:
    extraArgs:
      bind-address: 0.0.0.0
    image: registry.k8s.io/kube-controller-manager:v1.34.2
  coreDNS:
    disabled: true
  etcd:
    advertisedSubnets:
      - 192.168.42.0/26
    ca:
      crt: '{{ ENV[".cluster.etcd.ca.crt"] }}'
      key: '{{ ENV[".cluster.etcd.ca.key"] }}'
    extraArgs:
      listen-metrics-urls: http://0.0.0.0:2381

      # do not wake up CPU so often
      heartbeat-interval: "500"
      election-timeout: "5000"
  proxy:
    disabled: true
    image: registry.k8s.io/kube-proxy:v1.34.2
  scheduler:
    config:
      apiVersion: kubescheduler.config.k8s.io/v1
      kind: KubeSchedulerConfiguration
      profiles:
        - schedulerName: default-scheduler
          plugins:
            score:
              disabled:
                - name: ImageLocality
          pluginConfig:
            - name: PodTopologySpread
              args:
                defaultingType: List
                defaultConstraints:
                  - maxSkew: 1
                    topologyKey: kubernetes.io/hostname
                    whenUnsatisfiable: ScheduleAnyway
    extraArgs:
      bind-address: 0.0.0.0
    image: registry.k8s.io/kube-scheduler:v1.34.2
  secretboxEncryptionSecret: '{{ ENV[".cluster.secretboxEncryptionSecret"] }}'
  serviceAccount:
    key: '{{ ENV[".cluster.serviceAccount.key"] }}'
    # {% endif %}
---
apiVersion: v1alpha1
kind: VolumeConfig
name: EPHEMERAL
provisioning:
  diskSelector:
    match: system_disk
  minSize: 128GB
  maxSize: 128GB
---
apiVersion: v1alpha1
kind: UserVolumeConfig
name: rook-ceph
provisioning:
  diskSelector:
    match: system_disk
  minSize: 1GB
  maxSize: 1GB
---
apiVersion: v1alpha1
kind: UserVolumeConfig
name: extra
provisioning:
  diskSelector:
    match: system_disk
  minSize: 1GB
  grow: true
  # vim:ft=yaml
